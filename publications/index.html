<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=2" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Kishalay Das | publications</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  

 <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">
    <span class="site-title">
        
        <strong>Kishalay</strong> Das
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <a class="page-link" href="../index.html">Home</a>
        <a class="page-link" href="#">Publications</a>
        <a class="page-link" href="../Education/index.html">Education</a>
        <a class="page-link" href="../Experience/index.html">Experience</a>
          <!--<a class="page-link" href="../misc/index.html">Misc</a>-->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <!-- <h5 class="post-description">Publications by categories in reversed chronological order. Generated by jekyll-scholar.</h5> -->
  </header>

  <article class="post-content publications clearfix">

      <p> You can also find my articles on my <a target="_blank" href="https://scholar.google.com/citations?user=AMP0uJsAAAAJ&hl=en">Google Scholar profile.</a></p>

<h3 class="year">2023</h3>
<ol class="bibliography">

<li>
<div id="uai_2023">
    <span class="title"><strong>CrysMMNet: Multimodal Representation for Crystal Property Prediction.</strong></span>
    <span class="author">
      <u>Kishalay Das</u>, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhattacharjee and Niloy Ganguly
    </span>

    <span class="periodical">

        <em> UAI 2023.[Poster Presentation] <b> (acceptance rate of 31%) </b> </em>
        <!--<a href="https://www.scimagojr.com/journalsearch.php?q=21100850798&amp;tip=sid&amp;exact=no" title="SCImago Journal &amp; Country Rank"><img border="0" src="https://www.scimagojr.com/journal_img.php?id=21100850798" alt="SCImago Journal &amp; Country Rank"  /></a>-->
    </span>


  <span class="links">

<!--    [<a class="abstract">Abs</a>]-->
    [<a href="https://proceedings.mlr.press/v216/das23a.html" target="">Paper</a>]
    [<a href="https://openreview.net/forum?id=06jLJiUAKX" target="">OpenReview</a>]
    [<a href="https://arxiv.org/pdf/2307.05390.pdf" target="_blank">arXiv</a>]
    [<a href="../assets/pdf/UAI2023/605_das.pdf" target="">Poster</a>]
    [<a href="https://github.com/kdmsit/crysmmnet" target="">Code</a>]
    [<a href="https://youtu.be/dJSCCG31mEI" target="">Vlog</a>]
  </span>

  <!-- Hidden abstract block -->

<!--  <span class="abstract hidden">-->
<!--    <p>-->
<!--        Machine Learning models have emerged as a powerful tool for fast and accurate prediction of different crystalline properties.-->
<!--        Exiting state-of-the-art models rely on a single modality of crystal data i.e crystal graph structure, where they construct multi-graph by establishing edges between nearby atoms in 3D space and apply GNN to learn materials representation.-->
<!--        Thereby, they encode local chemical semantics around the atoms successfully but fail to capture important global periodic structural information like space group number, crystal symmetry, rotational information etc, which influence different crystal properties.-->
<!--        In this work, we leverage textual descriptions of materials to model global structural information into graph structure to learn a more robust and enriched representation of crystalline materials.-->
<!--        To this effect, we first curate a textual dataset for crystalline material databases containing descriptions of each material. Further, we propose CrysMMNet, a simple multi-modal framework, which fuses both structural and textual representation together to generate a joint multimodal representation of crystalline materials.-->
<!--        We conduct extensive experiments on benchmark datasets across ten different properties to show that CrysMMNet outperforms existing state-of-the-art baseline methods with a good margin. We also observe fusing textual representation with crystal graph structure provides consistent improvement for all the SOTA GNN models compared to their own vanilla version.-->
<!--        We are going to share the textual dataset, that we have curated for both the benchmark material databases with the community for future use.-->
<!--    </p>-->
<!--  </span>-->

</div>
</li>

<li>
<div id="aaai_2023">
    <span class="title"><strong>CrysGNN : Distilling pre-trained knowledge to enhance property prediction for crystalline materials.</strong></span>
    <span class="author">
      <u>Kishalay Das</u>, Bidisha Samanta, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhattacharjee and Niloy Ganguly
    </span>

    <span class="periodical">

        <em> AAAI 2023.[Oral Presentation] <b> (acceptance rate of 19.6%) </b>, ML4Materials Workshop @ ICLR-2023  </em>
        <!--<a href="https://www.scimagojr.com/journalsearch.php?q=21100850798&amp;tip=sid&amp;exact=no" title="SCImago Journal &amp; Country Rank"><img border="0" src="https://www.scimagojr.com/journal_img.php?id=21100850798" alt="SCImago Journal &amp; Country Rank"  /></a>-->
    </span>


  <span class="links">

<!--    [<a class="abstract">Abs</a>]-->
      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25892" target="_blank">Paper</a>]
      [<a href="../assets/pdf/AAAI2023/CrysGNN_Slides.pdf" target="_blank">Slide</a>]
      [<a href="https://github.com/kdmsit/crysgnn.git" target="_blank">Code</a>]
      [<a href="../assets/pdf/AAAI2023/CrysGNN_AAAI2023_poster.pdf" target="_blank">Poster</a>]
      [<a href="https://arxiv.org/abs/2301.05852" target="_blank">arXiv</a>]
      [<a href="https://youtu.be/J8rXFUlDrLk" target="_blank">Video</a>]
  </span>

  <!-- Hidden abstract block -->

<!--  <span class="abstract hidden">-->
<!--    <p>-->
<!--        In recent years, graph neural network (GNN) based approaches have emerged as a powerful technique to encode complex topological structure of crystal materials in an enriched representation space.-->
<!--        These models are often supervised in nature and using the property-specific training data, learn relationship between crystal structure and different properties like formation energy, bandgap, bulk modulus, etc.-->
<!--        Most of these methods require a huge amount of property-tagged data to train the system which may not be available for different properties. However, there is an availability of a huge amoun of crystal data with its chemical composition and structural bonds.-->
<!--        To leverage these untapped data, this paper presents CrysGNN, a new pre-trained GNN framework for crystalline materials, which captures both node and graph level structural information of crystal graphs using a huge amount of unlabelled material data.-->
<!--        Further, we extract distilled knowledge from CrysGNN and inject into different state of the art property predictors to enhance their property prediction accuracy. We conduct extensive experiments to show that with distilled knowledge from the pre-trained model, all the SOTA algorithms are able to outperform their own vanilla version with good margins.-->
<!--        We also observe that the distillation process provides significant improvement over the conventional approach of finetuning the pre-trained model. We will release the pre-trained model along with the large dataset of 800K crystal graph which we carefully curated; so that the pre-trained model can be plugged into any existing and upcoming models to enhance their prediction accuracy.-->
<!--    </p>-->
<!--  </span>-->

</div>
</li>


</ol>

<h3 class="year">2022</h3>
<ol class="bibliography">
<li>
<div id="year_2022">

    <span class="title"><strong>CrysXPP: An Explainable Property Predictor for Crystalline Material</strong></span>
    <span class="author">
      <u>Kishalay Das</u>, Bidisha Samanta, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhattacharjee and Niloy Ganguly
    </span>

    <span class="periodical">

        <em> NPJ Computational Materials (Nature) Journal,2022. <b> (Impact Factor: 13.2) </b> </em>
        <!--<a href="https://www.scimagojr.com/journalsearch.php?q=21100850798&amp;tip=sid&amp;exact=no" title="SCImago Journal &amp; Country Rank"><img border="0" src="https://www.scimagojr.com/journal_img.php?id=21100850798" alt="SCImago Journal &amp; Country Rank"  /></a>-->
    </span>


  <span class="links">

<!--    [<a class="abstract">Abs</a>]-->
    [<a href="https://www.nature.com/articles/s41524-022-00716-8.pdf" target="_blank">Paper</a>]
    [<a href="https://github.com/kdmsit/crysxpp.git" target="_blank">Code</a>]
    [<a target="_blank" href="../assets/pdf/CRYSXPP.pdf">Slides</a>]
    [<a href="https://www.youtube.com/watch?v=Kyrpj9cSkkM" target="_blank" >Video</a>]
    [<a href="https://medium.com/@cnerg.iitkgp/crysxpp-an-explainable-property-predictor-for-crystalline-materials-28d90cef13f3" target="_blank" >Blog</a>]
    [<a href="https://cnerg-iitkgp.github.io/ml/crysxpp/" target="_blank" >Page</a>]
  </span>

  <!-- Hidden abstract block -->

<!--  <span class="abstract hidden">-->
<!--    <p>-->
<!--        We present a deep-learning framework, CrysXPP, to allow rapid prediction of electronic, magnetic and elastic properties of a wide range of materials with reasonable precision.-->
<!--        Although our work is consistent with several recent attempts to build deep learning-based property predictors, it overcomes some of their limitations.-->
<!--        CrysXPP lowers the need for a large volume of tagged data to train a deep learning model by intelligently designing an autoencoder CrysAE and passing the structural information to the property prediction process.-->
<!--        The autoencoder in turn is trained on a huge volume of untagged crystal graphs, the designed loss function helps in capturing all their important structural and chemical information.-->
<!--        Moreover, CrysXPP uses only a small amount of tagged data for property prediction, and also trains a feature selector that provides interpretability to the results obtained.-->
<!--        We demonstrate that CrysXPP convincingly performs better than all the competing and recent baseline algorithms across seven diverse set of properties.-->
<!--        Most notably, when given a small amount of experimental data, CrysXPP is consistently able to outperform conventional DFT.-->
<!--        We release the large pretrained model CrysAE so that it could be fine-tuned using small amount of tagged data by the research community on various applications with restricted data source.-->
<!--    </p>-->
<!--  </span>-->

</div>
</li>
</ol>


<h3 class="year">2020</h3>
<ol class="bibliography"><li>
<div id="year_2020">
  
    <span class="title"><strong>Hypergraph Attention Isomorphism Network by Learning Line Graph Expansion</strong></span>
    <span class="author">
        Sambaran Bandyopadhyay, <u>Kishalay Das</u>, and M Narasimha Murty
    </span>

    <span class="periodical">
    
      <em>IEEE International Conference on Big Data,</em> 2020
    
    </span>

  <span class="links">
  
<!--    [<a class="abstract">Abs</a>]-->
    [<a href="https://ieeexplore.ieee.org/abstract/document/9378335" target="_blank">PDF</a>]
    [<a href="https://github.com/kdmsit/HAIN.git" target="_blank">Code</a>]
    [<a class="menulink" target="_blank" href="../assets/pdf/HAIN.pdf">Slides</a>]
    [<a href="https://www.youtube.com/watch?v=33XLw6LyoVU" target="_blank">Video</a>]
  </span>
  <!-- Hidden abstract block -->
  
<!--  <span class="abstract hidden">-->
<!--    <p> Graph neural networks (GNNs) are able to achieve state-of-the-art performance for node representation and classification in a network.-->
<!--        But, most of the existing GNNs can be applied to simple graphs, where an edge connects only a pair of nodes.-->
<!--        Studies have shown that hypergraphs are effective to model real-world relationships which are of higher order in nature.-->
<!--        Recently, graph neural networks are proposed for hypergraphs, but they implicitly use clique or star expansions to convert the hypergraph to a simple graph, or use computationally expensive hypergraph Laplacian.-->
<!--        In this work, we propose a novel hypergraph neural network for semi-supervised hypernode classification, which operates directly on the hypergraphs with varying hyperedge sizes.-->
<!--        Within each layer, it indirectly works on the line graph of the given hypergraph, without actually forming the line graph explicitly.-->
<!--        Moreover, it also employs a self-attention mechanism to learn the weights of those edge relationships. Experimentally, HAIN is able to improve the state-of-the-art hypernode classification performance on all the datasets we use.</p>-->
<!--  </span>-->
</div>
</li>
<li>
<div id="year_2020">

    <span class="title"><strong>Line Hypergraph Convolution Network: Applying Graph Convolution for Hypergraphs</strong></span>
    <span class="author">
        Sambaran Bandyopadhyay, <u>Kishalay Das</u>, and M Narasimha Murty
    </span>

    <span class="periodical">

      <em>arXiv,</em> 2020

    </span>

  <span class="links">

<!--    [<a class="abstract">Abs</a>]-->
    [<a href="https://arxiv.org/pdf/2002.03392.pdf" target="_blank">PDF</a>]
    [<a href="https://github.com/kdmsit/LHCN.git" target="_blank">Code</a>]
  </span>
  <!-- Hidden abstract block -->

<!--  <span class="abstract hidden">-->
<!--    <p> Network representation learning and node classification in graphs got significant attention due to the invent of different types graph neural networks.-->
<!--        Graph convolution network (GCN) is a popular semi-supervised technique which aggregates attributes within the neighborhood of each node.-->
<!--        Conventional GCNs can be applied to simple graphs where each edge connects only two nodes. But many modern days applications need to model high order relationships in a graph.-->
<!--        Hypergraphs are effective data types to handle such complex relationships. In this paper, we propose a novel technique to apply graph convolution on hypergraphs with variable hyperedge sizes.-->
<!--        We use the classical concept of line graph of a hypergraph for the first time in the hypergraph learning literature.-->
<!--        Then we propose to use graph convolution on the line graph of a hypergraph. Experimental analysis on multiple real world network datasets shows the merit of our approach compared to state-of-the-arts.</p>-->
<!--  </span>-->
</div>
</li>
</ol>

  </article>

</div>

      </div>
    </div>

  <footer>
        <tfoot align="center">
        <a href="https://clustrmaps.com/site/1bidq" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=INowEJFFw80_haaM45UlFC2Wib1YCxnVpH-8ZxPx_0Y&cl=ffffff" width="20" height="10"></a>
        @ Copyright 2021 Kishalay Das.
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
    </tfoot>
    </footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="http://localhost:4000/al-folio/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Inconsolata">


<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>



  </body>

</html>
